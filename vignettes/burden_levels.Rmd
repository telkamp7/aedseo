---
title: "Seasonal Burden Levels"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Seasonal Burden Levels}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, warning=FALSE, message=FALSE}
library(aedseo)
```

To provide a concise overview of how the `seasonal_burden_levels()` algorithm operates, we utilize the same example data presented
in the `vignette("aedseo")`. The plot below illustrates the two methods available for estiming burden levels in the
`combined_seasonal_output()` function:

- **`intensity_levels`**: Intended for within season classification of observations.
- **`peak_levels`**: Intended for comparing the height of peaks between seasons.

The disease-specific threshold is the `very low` breakpoint for both methods. Breakpoints are named as the upper bounds for the burden levels.

```{r, echo = FALSE}
withr::local_seed(222)
# Construct an 'tsd' object with time series data
tsd_data_clean <- generate_seasonal_data(
  years = 3,
  start_date = as.Date("2021-10-18"),
  amplitude = 2000,
  mean = 2000,
  phase = 0,
  time_interval = "week"
)

# Run models
intensity_levels <- seasonal_burden_levels(
  tsd = tsd_data_clean,
  disease_threshold = 140,
  method = "intensity_levels",
  conf_levels = 0.95
)
peak_levels <- seasonal_burden_levels(
  tsd = tsd_data_clean,
  disease_threshold = 140,
  method = "peak_levels",
  conf_levels = c(0.4, 0.9, 0.975),
  n_peak = 8
)

# Create data frame
burden_levels_df <- data.frame(
  Level = names(
    c(intensity_levels$values,
      peak_levels$values
    )
  ),
  Threshold = c(
    intensity_levels$values,
    peak_levels$values
  ),
  Method = c(
    rep("Intensity Levels", 4),
    rep("Peak Levels", 4)
  )
)
burden_levels_df$Level <- factor(
  burden_levels_df$Level,
  levels = c("high", "medium", "low", "very low")
)

# Calculate y_tics
y_tics_log10 <- pretty(c(log10(burden_levels_df$Threshold)))
y_tics_levels <- 10^(y_tics_log10)

# For each tic, find the closest magnitude to round correctly
round_to_nearest <- function(x) {
  magnitude <- 10^floor(log10(x))
  plyr::round_any(x, accuracy = magnitude)
}
y_tics <- sapply(y_tics_levels, round_to_nearest)

# Round max value
rounded_max_threshold <- (round(max(burden_levels_df$Threshold) / 1000) * 1000) + 1000
y_tics <- c(y_tics[-5], rounded_max_threshold)

# Create the plot
burden_levels_df |>
  ggplot2::ggplot(ggplot2::aes(x = 0, y = Threshold, linetype = Level, color = Level)) +
  ggplot2::geom_hline(
    ggplot2::aes(yintercept = Threshold, linetype = Level, color = Level),
    linewidth = 1
  ) +
  ggplot2::labs(
    x = NULL,
    y = "Observations",
    linetype = "Aedseo levels",
    color = "Aedseo levels"
  ) +
  ggplot2::scale_linetype_manual(
    values = c(
      "very low" = "dotted",
      "low" = "dashed",
      "medium" = "longdash",
      "high" = "solid"
    )
  ) +
  ggplot2::scale_color_manual(
    values = c(
      "very low" = "#44ce1b",
      "low" = "#bbdb44",
      "medium" = "#f2a134",
      "high" = "#e51f1f"
    )
  ) +
  ggplot2::facet_wrap(~ Method, ncol = 2) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    axis.text.x = ggplot2::element_blank(),
    axis.ticks.x = ggplot2::element_blank(),
    legend.position = "right",
    legend.key.width = grid::unit(2, "cm"),
    axis.title = ggplot2::element_text(size = 12)

  ) +
  ggplot2::scale_y_log10(
    breaks = y_tics,
    limits = range(y_tics),
    labels = scales::label_comma(big.mark = ".", decimal.mark = ",")
  )
```

## Methodology

The methodology used to define the burden levels of seasonal epidemics is based on observations from previous seasons.
Historical data from all available seasons is used to establish the levels for the current season.
This is done by:

- Using `n` highest (peak) observations from each season.
- Selecting only observations if they surpass the disease-specific threshold.
- Weighting the observations such that recent observations have a greater influence than older observations.
- A proper distribution (log-normal, weibull and exponential are currently implemented) is fitted to the weighted
 `n` peak observations. The selected distribution with the fitted parameters is used to calculate percentiles to be used as breakpoints.
- Burden levels can be defined by two methods:
  - `peak_levels` which models the height of the seasonal peaks. Using the log-normal distribution without weights is similar
  to the default in [mem](https://github.com/lozalojo/mem).
 - `intensity_levels` which models the within season levels. The highest breakpoint is coinciding with the `peak_levels` method.
 Intermediate breakpoints are evenly distributed on a logaritmic scale, between the `very low` and `high` breakpoints,
 to give the same relative difference between the breakpoints.

The model is implemented in the `seasonal_burden_levels()` function of the `aedseo` package.
In the following sections we will describe the arguments for the function and how the model is build.

#### Peak observations
`n_peak` observations are used to describe the number of highest observations that are used from each season.
The default of `n_peak` is `6` - this is similar to using latest five seasons in `mem`.

#### Weighting
A `decay_factor` is implemented to give more weight to recent seasons as they are often more indicative of current and future trends.
As time progresses, the relevance of older seasons may decrease due to changes in factors like testing recommendation, population immunity,
virus mutations, or intervention strategies. Weighting older seasons less reflects this reduced relevance.
The default `decay_factor` is `0.8`, allowing the model to be responsive to recent changes without being overly
sensitive to short-term fluctuations.
The optimal decay factor can vary depending on the variability and trends within the data. For datasets where seasonal
patterns are highly stable, a higher decay factor (i.e. longer memory) might be appropriate. Conversely, data that has changed a lot across
seasons, a lower factor could improve predictions.
From time-series analysis $1/(1-decay_factor)$ is the effective memory so that the default corresponds to five seasons.

#### Distribution and optimisation
`family` is the argument used to select which distribution the `n_peak` observations should be fitted to, users can
choose between `lnorm`, `weibull` and `exp` distributions. The log-normal distribution theoretically
aligns well with the nature of epidemic data, which often exhibits multiplicative growth patterns.
In our optimization process, we evaluated the distributions to determine their performance in fitting Danish non-sentinel
cases and hospitalisation data for RSV, SARS-CoV-2 and Influenza (A and B). All three distributions had comparable
weighted likelihood values during optimisation, hence we did not see any statistical significant difference in their performance.

The model uses the `fit_percentiles()` function which employs the `stats::optim` for estimating the parameters that maximizes the weighted likelihood.
The `optim_method` argument can be passed to `seasonal_burden_levels()`, default is `Nelder-Mead` but other methods can be selected,
see `?fit_percentiles`.

#### Burden levels
`method` is the argument used to select one of the two methods `intensity_levels`(default) and `peak_levels`.
Both methods return percentile(s) from the fitted distribution which are used to define the breakpoins for the burden levels.
Breakpoints are named `very low`, `low`, `medium` and `high` and define the upper bound of the corresponding burden level.

- `intensity_levels` takes one percentile as argument, representing the highest breakpoint.
  The default is set at a 95% percentile. The disease-specific threshold
  determines the `very low` breakpoint. The `low` and `medium` breakpoints are calculated to give identical relative
  increases between the `very low` and `high` breakpoints.

- `peak_levels` takes three percentiles as argument, representing the `low`, `medium` and `high` breakpoints.
  The default percentiles are 40%, 90%, and 97.5% to align with the parameters used in [mem](https://github.com/lozalojo/mem).
  The disease-specific threshold defines the `very low` breakpoint.

## Applying the `seasonal_burden_levels()` algorithm

To apply the `seasonal_burden_levels()` algorithm, data needs to be transformed into a `tsd` object.
```{r, include = FALSE}
withr::local_seed(222)
# Construct 'tsd' objects with time series data
tsd_data_noise <- generate_seasonal_data(
  years = 4,
  start_date = as.Date("2021-10-18"),
  amplitude = 2000,
  mean = 2000,
  phase = 0,
  noise_sd = 200,
  time_interval = "week"
)

tsd_data_noise_and_pos_trend <- generate_seasonal_data(
  years = 4,
  start_date = as.Date("2021-10-18"),
  amplitude = 2000,
  mean = 2000,
  phase = 0,
  noise_sd = 200,
  trend_rate = 1.002,
  time_interval = "week"
)

tsd_data_noise_and_neg_trend <- generate_seasonal_data(
  years = 4,
  start_date = as.Date("2021-10-18"),
  amplitude = 2000,
  mean = 2000,
  phase = 0,
  noise_sd = 200,
  trend_rate = 0.99,
  time_interval = "week"
)

# Remove days after week 20 in last season to get only 4 seasons data
tsd_data_noise <- tsd_data_noise |>
  dplyr::filter(time <= "2025-05-12")
tsd_data_noise_and_pos_trend <- tsd_data_noise_and_pos_trend |>
  dplyr::filter(time <= "2025-05-12")
tsd_data_noise_and_neg_trend <- tsd_data_noise_and_neg_trend |>
  dplyr::filter(time <= "2025-05-12")

```

### Use the `intensity_levels` method
```{r}
intensity_levels_n <- seasonal_burden_levels(
  tsd = tsd_data_noise,
  disease_threshold = 140,
  method = "intensity_levels",
  conf_levels = 0.95
)
print(intensity_levels_n)
```

```{r, include = FALSE}
intensity_levels_n_pos_t <- seasonal_burden_levels(
  tsd = tsd_data_noise_and_pos_trend,
  disease_threshold = 140,
  method = "intensity_levels",
  conf_levels = 0.95
)
intensity_levels_n_neg_t <- seasonal_burden_levels(
  tsd = tsd_data_noise_and_neg_trend,
  disease_threshold = 140,
  method = "intensity_levels",
  conf_levels = 0.95
)
```

### Use the `peak_levels` method
`mem` uses the `n` highest observations from each epidemic period to fit the parameters of the distribution,
where `n = 30/seasons`. The data has four seasons, to align with mem, we use `n_peak = 8`
```{r}
peak_levels_n <- seasonal_burden_levels(
  tsd = tsd_data_noise,
  disease_threshold = 140,
  method = "peak_levels",
  conf_levels = c(0.4, 0.9, 0.975),
  n_peak = 8
)
print(peak_levels_n)
```

```{r, include = FALSE}
peak_levels_n_pos_t <- seasonal_burden_levels(
  tsd = tsd_data_noise_and_pos_trend,
  disease_threshold = 140,
  method = "peak_levels",
  conf_levels = c(0.4, 0.9, 0.975),
  n_peak = 8
)

peak_levels_n_neg_t <- seasonal_burden_levels(
  tsd = tsd_data_noise_and_neg_trend,
  disease_threshold = 140,
  method = "peak_levels",
  conf_levels = c(0.4, 0.9, 0.975),
  n_peak = 8
)
```

### Use the [Moving Epidemic Method (mem)](https://github.com/lozalojo/mem)
mem is run with default arguments.
```{r, include = FALSE}
data_list <- list(
  tsd_data_noise = tsd_data_noise,
  tsd_data_noise_and_pos_trend = tsd_data_noise_and_pos_trend,
  tsd_data_noise_and_neg_trend = tsd_data_noise_and_neg_trend
)
```

```{r}
# Run mem algorithm
mem_thresholds <- purrr::map(data_list, ~ {
  mem_data <- .x |>
    dplyr::mutate(season = aedseo::epi_calendar(time),
                  week = lubridate::isoweek(time)) |>
    dplyr::select(-time) |>
    tidyr::pivot_wider(names_from = season, values_from = observation) |>
    dplyr::select(-week)
  # Run mem
  mem_result <- mem::memmodel(mem_data, i.seasons = 4)
  # Extract thresholds
  mem_thresholds <- tibble::tibble(
    `epidemic threshold \n (start)` = mem_result$epidemic.thresholds[1],
    `epidemic threshold \n (end)` = mem_result$epidemic.thresholds[2],
    `medium` = mem_result$intensity.thresholds[1],
    `high` = mem_result$intensity.thresholds[2],
    `very high` = mem_result$intensity.thresholds[3]
  )
})
```
| Name                      | Value |
|---------------------------|-------|
| epidemic threshold (start)| 3004  |
| epidemic threshold (end)  | 2975  |
| medium                    | 3902  |
| high                      | 4206  |
| very high                 | 4347  |

## Compare `intensity_levels`, `peak_levels` and `mem` algorithms
The same data is created with following combinations:

- noise
- noise and positive trend
- noise and negative trend

These combinations are selected as it is realistic for real world data to have noise, and differentiation between
trend can occur declining or inclining between seasons.
Breakpoints for season *2024/2025* calculated based on the three previous seasons.

### Aedseo levels
```{r, echo = FALSE, fig.width=10, fig.height=8, dpi=300}
#### Create data frames
burden_levels_df <- tibble::tibble(
  Level = names(
    c(intensity_levels_n$values,
      intensity_levels_n_pos_t$values,
      intensity_levels_n_neg_t$values,
      peak_levels_n$values,
      peak_levels_n_pos_t$values,
      peak_levels_n_neg_t$values
    )
  ),
  Threshold = c(
    intensity_levels_n$values,
    intensity_levels_n_pos_t$values,
    intensity_levels_n_neg_t$values,
    peak_levels_n$values,
    peak_levels_n_pos_t$values,
    peak_levels_n_neg_t$values
  ),
  Method = c(
    rep("Intensity Levels \n (noise)", 4),
    rep("Intensity Levels \n (noise and \n positive trend)", 4),
    rep("Intensity Levels \n (noise and \n negative trend)", 4),
    rep("Peak Levels \n (noise)", 4),
    rep("Peak Levels \n (noise and \n positive trend)", 4),
    rep("Peak Levels \n (noise and \n negative trend)", 4)
  )
)

##### Adjustments for plot
burden_levels_df <- burden_levels_df |>
  dplyr::mutate(algorithm = stringr::str_extract(Method, ".*Levels"))

burden_levels_df$Level <- factor(
  burden_levels_df$Level,
  levels = c(
    "high",
    "medium",
    "low",
    "very low"
  )
)

# Calculate y_tics
y_tics_log10 <- pretty(c(log10(burden_levels_df$Threshold)))
y_tics_levels <- 10^(y_tics_log10)

# For each tic, find the closest magnitude to round correctly
round_to_nearest <- function(x) {
  magnitude <- 10^floor(log10(x))
  plyr::round_any(x, accuracy = magnitude)
}
y_tics <- sapply(y_tics_levels, round_to_nearest)

# Round max value
rounded_max_threshold <- round(max(burden_levels_df$Threshold) / 1000) * 1000
y_tics <- c(y_tics[-5], rounded_max_threshold, rounded_max_threshold + 2000)

#### Plot
burden_levels_df |>
  ggplot2::ggplot(ggplot2::aes(x = 0, y = Threshold, linetype = Level, color = Level)) +
  ggplot2::geom_hline(
    ggplot2::aes(yintercept = Threshold, linetype = Level, color = Level),
    linewidth = 1
  ) +
  ggplot2::labs(
    x = NULL,
    y = "Observations",
    linetype = "Aedseo levels",
    color = "Aedseo levels"
  ) +
  ggplot2::scale_linetype_manual(
    values = c(
      "very low" = "dotted",
      "low" = "dashed",
      "medium" = "longdash",
      "high" = "solid"
    )
  ) +
  ggplot2::scale_color_manual(
    values = c(
      "very low" = "#44ce1b",
      "low" = "#bbdb44",
      "medium" = "#f2a134",
      "high" = "#e51f1f"
    )
  ) +
  ggplot2::facet_wrap(~ Method, nrow = 2) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    axis.text.x = ggplot2::element_blank(),
    axis.ticks.x = ggplot2::element_blank(),
    legend.position = "right",
    legend.key.width = grid::unit(2, "cm")
  ) +
  ggplot2::scale_y_log10(
    breaks = y_tics,
    limits = range(y_tics),
    labels = scales::label_comma(big.mark = ".", decimal.mark = ",")
  )
```

### mem levels
```{r, echo = FALSE, fig.width=10, fig.height=4}
mem_levels_df <- tibble::tibble(
  Level = names(
    c(mem_thresholds$tsd_data_noise,
      mem_thresholds$tsd_data_noise_and_pos_trend,
      mem_thresholds$tsd_data_noise_and_neg_trend
    )
  ),
  Threshold = c(
    as.numeric(mem_thresholds$tsd_data_noise),
    as.numeric(mem_thresholds$tsd_data_noise_and_pos_trend),
    as.numeric(mem_thresholds$tsd_data_noise_and_neg_trend)
  ),
  Method = c(
    rep("mem Levels \n (noise)", 5),
    rep("mem Levels \n (noise and \n positive trend)", 5),
    rep("mem Levels \n (noise and \n negative trend)", 5)
  )
)

# Adjustments for plot
mem_levels_df$Level <- factor(
  mem_levels_df$Level,
  levels = c(
    "very high",
    "high",
    "medium",
    "epidemic threshold \n (start)",
    "epidemic threshold \n (end)"
  )
)

mem_levels_df |>
  ggplot2::ggplot(ggplot2::aes(x = 0, y = Threshold, linetype = Level, color = Level)) +
  ggplot2::geom_hline(
    ggplot2::aes(yintercept = Threshold, linetype = Level, color = Level),
    linewidth = 1
  ) +
  ggplot2::labs(
    x = NULL,
    y = "Observations",
    linetype = "mem level",
    color = "mem level"
  ) +
  ggplot2::scale_linetype_manual(
    values = c(
      "medium" = "longdash",
      "high" = "solid",
      "very high" = "dotdash",
      "epidemic threshold \n (start)" = "solid",
      "epidemic threshold \n (end)" = "solid"
    )
  ) +
  ggplot2::scale_color_manual(
    values = c(
      "medium" = "#f2a134",
      "high" = "#e51f1f",
      "very high" = "#891212",
      "epidemic threshold \n (start)" = "#bbdb44",
      "epidemic threshold \n (end)" = "#44ce1b"
    )
  ) +
  ggplot2::facet_wrap(~ Method, ncol = 6) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    axis.text.x = ggplot2::element_blank(),
    axis.ticks.x = ggplot2::element_blank(),
    legend.position = "right",
    legend.key.width = grid::unit(2, "cm")
  ) +
  ggplot2::scale_y_log10(
    breaks = y_tics,
    limits = range(y_tics),
    labels = scales::label_comma(big.mark = ".", decimal.mark = ",")
  )
```

Upon examining all methods and data combinations, it becomes clear that the `intensity_levels` approach establishes
levels covering the entire set of observations from previous seasons. In contrast, the `peak_levels` and `mem` methods
define levels solely based on the highest observations within each season.

The highest observations for the *2024/2025* season for each data set are:

| Data                      | Value |
|---------------------------|-------|
| Noise                     | 4456  |
| Noise and positive trend  | 6048  |
| Noise and negative trend  | 3735  |

In relation to these highest observations and upon further examination, we observe the following:

1. Plots with Noise and Noise with Positive Trend:

- Both `peak_levels` and `mem` compress all the levels into rather high values. This occurs because observations
remain consistently elevated across all three seasons, causing these methods to overlook the remaining
observations.

2. Data with Noise and Positive Trend:

- All three methods exhibit higher burden levels, indicating that they successfully capture the exponentially
increasing trend between seasons.

3. Data with Noise and Negative Trend:

- As observations exponentially decrease between seasons (with the highest observation this season being 3,735),
we expect the burden levels to be lower.  This expectation is met across all three methods. However, the weighting
of seasons in `intensity_levels` and `peak_levels` leads to older seasons having less impact on the burden levels as
we progress forward in time. On the other hand, `mem` includes all high observations from the previous 10 seasons
without diminishing the importance of older seasons, which results in sustained `very high` burden levels.

- Notably, in the `mem` method, the epidemic thresholds are positioned above the `medium` burden level.
This means that the epidemic period begins only when the burden reaches the range of high observations
observed in previous seasons.

This concludes, that using the `peak_levels` and `mem` methods does not allow us to assess the burden before the season
reaches the range of high observations from previous seasons. In contrast, the `intensity_levels` method allows for
continuous monitoring of the burden of current observation rate throughout the entire season.
